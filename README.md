# ðŸ‘‹ Hi, Iâ€™m @TanyaDemi  

I am a **Data Engineer** with over a year of intensive training and hands-on practice in building **ETL pipelines, data integration, and automation**.  
Skilled in **SQL, Python, and Apache Airflow**, with experience designing schemas, staging layers, and DWH tables to deliver reliable analytical Data Marts.  

---

## ðŸ”¹ Key Experience & Skills  

- Built an **ETL pipeline with Apache Airflow**, orchestrating extraction from PostgreSQL, transformation, and loading into Vertica DWH.  
- Designed and implemented **staging and DWH layers** with dimension and fact tables for financial data.  
- Developed and tested **Airflow DAGs** for schema creation, data import, and incremental data mart updates.  
- Configured **Docker containers** to run Airflow and manage SQL scripts, including Python package installation.  
- Optimized **SQL queries** for data aggregation, partitioning, and performance.  
- Integrated with **Yandex.Cloud managed databases**, ensuring secure SSL connections.  
- Delivered a fully functioning **data mart** with aggregated financial metrics and reporting capabilities.  
- Experienced in building **Data Vault models** (Hubs, Links, Satellites) and delivering business-ready Data Marts.  

---

## ðŸ’¡ About Me  

I am an **open-minded and critical thinker**, making decisions based on facts.  

This mindset led me to advance my education in IT, starting with **Python and SQL**, and developing expertise in **ETL, data warehousing, and automation**.  

I am looking for a **full-time Data Engineer position** in a company where I can apply my knowledge, grow within a collaborative team, and contribute to impactful data solutions.  

---

## ðŸ“‚ Portfolio  

Check out my portfolio of academic data engineering projects here:  
ðŸ‘‰ [**Portfolio â€” Academic Projects**](https://github.com/TanyaDemi/Portfolio-Academic-Project)
