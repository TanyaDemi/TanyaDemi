ðŸ‘‹ Hi, Iâ€™m @TanyaDemi

I am a Junior Data Engineer with over a year of intensive training and hands-on practice in building ETL pipelines, data integration, and automation. Skilled in SQL, Python, and Apache Airflow, with experience designing schemas, staging layers, and DWH tables to deliver reliable analytical Data Marts.

ðŸ”¹ Key Experience & Skills

- Built an ETL pipeline with Apache Airflow, orchestrating extraction from PostgreSQL, transformation, and loading into Vertica DWH.
- Designed and implemented staging and DWH layers with dimension and fact tables for financial data.
- Developed and tested Airflow DAGs for schema creation, data import, and incremental data mart updates.
- Configured Docker containers to run Airflow and manage SQL scripts, including Python package installation.
- Optimized SQL queries for data aggregation, partitioning, and performance.
- Integrated with Yandex.Cloud managed databases, ensuring secure SSL connections.
- Delivered a fully functioning data mart with aggregated financial metrics and reporting capabilities.
- Experienced in building Data Vault models (Hubs, Links, Satellites) and delivering business-ready Data Marts.

ðŸ’¡ I am an open-minded and critical thinker, making decisions based on facts. 

This mindset led me to advance my education in IT, starting with Python and SQL, and developing expertise in ETL, data warehousing, and automation.
I am looking for a full-time Data Engineer position in a company where I can apply my knowledge, grow within a collaborative team, and contribute to impactful data solutions.


<!---
TanyaDemi/TanyaDemi is a âœ¨ special âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
